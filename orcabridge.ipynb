{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I define few critical concepts for Orcapod.\n",
    "\n",
    "* `Data` -- In Orcapod, smallest unit of `data` is a single `file`. Unlike many other computation pipeline system, Orcapod pipeline in principle does **not** operate on `data` that's not a file. In other words, `Oracpod` pipeline will **not** pass a data in memory from one node to another. Consequently, all operations and processing in Orcapod pipeline revolves around `file` (NOTE: this is a particularly strong/restrictive version of Oracpod pipeline. We may consider extending data to things like environment variable and command line arguments)\n",
    "* `Pathset` -- a unit of data that can be passed into a pod. A `pathset` consists of a file, a directory, or a collection of one or more file and directories.\n",
    "* `Packet` -- a single concrete instance of key-value pair, mapping packet key to a single `pathset`.\n",
    "* `Stream` -- a series of one or more `packets` flowing from a `data producer` to a `data consumer`. In a directed acyclic graph represneing an Orcapod `pipeline`, a `stream` corresponds to a *directed* edge connecting from a data source into a `data consumer` (e.g., `pod`)\n",
    "* `Data producer` and `data consumer` -- in the Orcapod data pipeline, data (in form of `packet` of data flowing inside a `stream`) flows from a `data producer` to a `data consumer`. Consequentially, a `data consumer` may in turn act as a `data producer` downstream\n",
    "* `Data source` -- Root level `data producer` (that is, the data originates from this `data producer` and it is not a `data consumer` of any stream). Typically `data source` is tied to a data storage, although you could have *procedural* `data source` where data packets are produced programatically.\n",
    "* `Tag` -- each `Packet` in a stream *may be* associated with a `tag` that helps to assign semantic identity to the particular `packet`. For example, a data `packet` for an experimental data may be associated with a `tag` of session ID. Note that while `tag` provides a convenient and often meaningful ways of identifying and referring to specific packet within a stream, it should **not** be considered to be the defining identity of the `packet`. Identity of the `packet` is strictly determined by the exact data content of the `packet`, and not by how you refer to it. Consequently, it may be that two packets with an identical content (and thus shared identity) are associated with distinct `tags` in a `stream`. Conversely, an identical `tag` may be associated with two distinct `packets` in a stream.  Typically, one would associate a unique `tag` for each packet in the stream.\n",
    "* `Operation` -- A *node* in the directed acyclic graph representing an Orcapod `pipeline`, corresponding to a step of data processing/transformation/computation. An `Operation` receives can be classified into either a `mapper` or a `pod` based on their role in `data provenance`.\n",
    "* `Mapper` -- A class of `operation` that does **not** result in creation/alteration of a new data -- that is, `operation` does **not** every create or modify a file *content*. More specifically, `Mapper` operation can not produce a path that was not already present in the input streams to the `mapper`. This feature ensures that a `mapper` is fundamentally not involved in the reproducibility of computation. Consequently, `mapper` information is not necessary for the maintenance of proper `data provenance` in a tree of computation. However, `mapper` plays critical role in the actual execution of a data pipeline, determining which data `packet` will be fed into operations in the pipeline directed acyclic graph (DAG). Note that as long as it doesn't modify the content of any file, a `mapper` may inspect the content of any file in a `packet` it receives and alter its behavior based on the content of the file. In other words, `mapper` may alter what data file(s) gets passed around without changing/creating any file based on a rule that depends on `tag`, `packet` key (`argument` name) and/or file content.\n",
    "* `Pod` (e.g. FunctionPod) -- fundamental unit of computation in Orcapod. `Pod` is the only class of `operation` that may create a new file. Critically, when operating within an Orcapod `pipeline`, a `pod` will **not** receive the `tag` information. Rather, `pod` must strictly operate on a single `packet`. An ideal `pod` will have completely deterministic behavior that only depends on the `packet` identity (that is, packet keys and `pathset` contents)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Orcabrdige?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Orcabridge` provide prototypal implementation of the above-defined key concepts in `orcapod`, with particular focus given to `stream`, `packet`, `tag`, `operation` (`pod` and `mapper`). This package provides the reference implementation of both synchronous and asynchronous `streams` as a sequence of `packets` associated with a `tag`. \n",
    "\n",
    "### Key limitations\n",
    "Being a very basic reference implementation with a goal of serving as a playground for conceptual and algorithmic development, there are a few notable limitations in `orcabridge`, lacking some important features that would be found in the full implementation of `orcapod`.\n",
    "\n",
    "* Limited `pathset` -- Only a very rudimentary implementation of a `pathset` can be found, where a typical `packet` would be a simple key-value pair where the value is a single file path. \n",
    "* `FunctionPod` in place of `pod` -- A ideal `pod` will represent a completely reproducible unit of computation with strict dependence on the input `packet` to the `pod`. However, in `orcabridge` is equivalated to a Python function -- even more specifically, the name assigned to the Python function. In otherwords, two `FunctionPods` are considered identical if they share the same function name. Quite obviously this is a gross simplification that can be trivially violated. However, for the intended purpose of `orcabridge`, this rather simplistic implementation/definition of `pod` should suffice to test all features in the `pipeline`. Consequently, to ensure that the pipeline operates as expected, **do not use the same name for two distinct functions**. Doing so will break the fundamental assumption of `FunctionPod` and lead to completely erradic behavior. On the other hand, it is ok to have one or more name used to refer to an identical function.\n",
    "* Different pipeline DAG defintion -- In `orcapod` the directed acyclic graph (DAG) for the `pipeline` should be defined using YAML file (or less frequently using API on `pipeline` struct in the Rust library). In `orcabridge` you will find that a `pipeline` DAG is defined dynamically through a series of application of `operation`. This is very much akin to how some DAG-based neural network library like TensorFlow defines a computation graph. While this works well for simple examples, it is rather difficult to track changes to the pipeline defined dynamically/programmatically using version control system. Since *how* you define the pipeline DAG is strictly speaking an orthogonal problem to the everything else that concerns the operation of the `pipeline`, no effort will be given to align the DAG definition in `orcabridge` and `orcapod`.\n",
    "* Limited usage of a `stream` -- Currently `orcabrdige` only support single producer single consumer (SCSP) `stream`x, whereas in `orcapod`, `stream` should support single producer multiple consumer (SPMC) paradigm. This can be somewhat overcome by using `Duplicator` mapper but this is fundamentally less efficient then pipeline implementation based on SPMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-26 04:16:26,865][INFO]: Connecting eywalker@at-database3.stanford.edu:3306\n",
      "[2025-04-26 04:16:26,984][INFO]: Connected eywalker@at-database3.stanford.edu:3306\n"
     ]
    }
   ],
   "source": [
    "import datajoint as dj\n",
    "dj.config['database.host'] = 'at-database3.stanford.edu'\n",
    "dj.config['database.user'] = 'eywalker'\n",
    "dj.conn()\n",
    "\n",
    "from orcabridge.dj.stream import FixedStreamFromTable\n",
    "from orcabridge.pod import FunctionPod\n",
    "from orcabridge.mapper import Join, MapKeys, MapTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.schema('enigma_orcabridge_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@schema\n",
    "class SampleData1(dj.Lookup):\n",
    "    definition = \"\"\"\n",
    "    # Sample data\n",
    "    animal_id: int unsigned  # Sample ID\n",
    "    ---\n",
    "    data1: varchar(255)  # path to data1\n",
    "    data2: varchar(255) # path to data2\n",
    "    \"\"\"\n",
    "    contents = [\n",
    "        (1, '/path/to/data1', '/path/to/data2'),\n",
    "        (2, '/path/to/data3', '/path/to/data4'),\n",
    "        (3, '/path/to/data5', '/path/to/data6'),\n",
    "        (4, '/path/to/data7', '/path/to/data8')\n",
    "    ]\n",
    "\n",
    "@schema\n",
    "class SampleData2(dj.Lookup):\n",
    "    definition = \"\"\"\n",
    "    # Sample data\n",
    "    subject_id: int unsigned  # Sample ID\n",
    "    ---\n",
    "    data3: varchar(255)  # path to data1\n",
    "    data4: varchar(255) # path to data2\n",
    "    \"\"\"\n",
    "    contents = [\n",
    "        (1, '/path/to/data9', '/path/to/data30'),\n",
    "        (3, '/path/to/data10', '/path/to/data62'),\n",
    "        (5, '/path/to/data9', '/path/to/data10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b>Sample data</b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">animal_id</p>\n",
       "                            <span class=\"djtooltiptext\">Sample ID</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">data1</p>\n",
       "                            <span class=\"djtooltiptext\">path to data1</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">data2</p>\n",
       "                            <span class=\"djtooltiptext\">path to data2</span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>1</td>\n",
       "<td>/path/to/data1</td>\n",
       "<td>/path/to/data2</td></tr><tr><td>2</td>\n",
       "<td>/path/to/data3</td>\n",
       "<td>/path/to/data4</td></tr><tr><td>3</td>\n",
       "<td>/path/to/data5</td>\n",
       "<td>/path/to/data6</td></tr><tr><td>4</td>\n",
       "<td>/path/to/data7</td>\n",
       "<td>/path/to/data8</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 4</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*animal_id    data1          data2         \n",
       "+-----------+ +------------+ +------------+\n",
       "1             /path/to/data1 /path/to/data2\n",
       "2             /path/to/data3 /path/to/data4\n",
       "3             /path/to/data5 /path/to/data6\n",
       "4             /path/to/data7 /path/to/data8\n",
       " (Total: 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SampleData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    <style type=\"text/css\">\n",
       "        .Table{\n",
       "            border-collapse:collapse;\n",
       "        }\n",
       "        .Table th{\n",
       "            background: #A0A0A0; color: #ffffff; padding:4px; border:#f0e0e0 1px solid;\n",
       "            font-weight: normal; font-family: monospace; font-size: 100%;\n",
       "        }\n",
       "        .Table td{\n",
       "            padding:4px; border:#f0e0e0 1px solid; font-size:100%;\n",
       "        }\n",
       "        .Table tr:nth-child(odd){\n",
       "            background: #ffffff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        .Table tr:nth-child(even){\n",
       "            background: #f3f1ff;\n",
       "            color: #000000;\n",
       "        }\n",
       "        /* Tooltip container */\n",
       "        .djtooltip {\n",
       "        }\n",
       "        /* Tooltip text */\n",
       "        .djtooltip .djtooltiptext {\n",
       "            visibility: hidden;\n",
       "            width: 120px;\n",
       "            background-color: black;\n",
       "            color: #fff;\n",
       "            text-align: center;\n",
       "            padding: 5px 0;\n",
       "            border-radius: 6px;\n",
       "            /* Position the tooltip text - see examples below! */\n",
       "            position: absolute;\n",
       "            z-index: 1;\n",
       "        }\n",
       "        #primary {\n",
       "            font-weight: bold;\n",
       "            color: black;\n",
       "        }\n",
       "        #nonprimary {\n",
       "            font-weight: normal;\n",
       "            color: white;\n",
       "        }\n",
       "\n",
       "        /* Show the tooltip text when you mouse over the tooltip container */\n",
       "        .djtooltip:hover .djtooltiptext {\n",
       "            visibility: visible;\n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "    <b>Sample data</b>\n",
       "        <div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "        <table border=\"1\" class=\"Table\">\n",
       "            <thead> <tr style=\"text-align: right;\"> <th> <div class=\"djtooltip\">\n",
       "                            <p id=\"primary\">subject_id</p>\n",
       "                            <span class=\"djtooltiptext\">Sample ID</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">data3</p>\n",
       "                            <span class=\"djtooltiptext\">path to data1</span>\n",
       "                        </div></th><th><div class=\"djtooltip\">\n",
       "                            <p id=\"nonprimary\">data4</p>\n",
       "                            <span class=\"djtooltiptext\">path to data2</span>\n",
       "                        </div> </th> </tr> </thead>\n",
       "            <tbody> <tr> <td>1</td>\n",
       "<td>/path/to/data9</td>\n",
       "<td>/path/to/data30</td></tr><tr><td>3</td>\n",
       "<td>/path/to/data10</td>\n",
       "<td>/path/to/data62</td></tr><tr><td>5</td>\n",
       "<td>/path/to/data9</td>\n",
       "<td>/path/to/data10</td> </tr> </tbody>\n",
       "        </table>\n",
       "        \n",
       "        <p>Total: 3</p></div>\n",
       "        "
      ],
      "text/plain": [
       "*subject_id    data3          data4         \n",
       "+------------+ +------------+ +------------+\n",
       "1              /path/to/data9 /path/to/data3\n",
       "3              /path/to/data1 /path/to/data6\n",
       "5              /path/to/data9 /path/to/data1\n",
       " (Total: 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SampleData2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now turn these two tables into table-based streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_stream1 = FixedStreamFromTable(SampleData1)\n",
    "table_stream2 = FixedStreamFromTable(SampleData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal_id': 1} {'data1': '/path/to/data1', 'data2': '/path/to/data2'}\n",
      "{'animal_id': 2} {'data1': '/path/to/data3', 'data2': '/path/to/data4'}\n",
      "{'animal_id': 3} {'data1': '/path/to/data5', 'data2': '/path/to/data6'}\n",
      "{'animal_id': 4} {'data1': '/path/to/data7', 'data2': '/path/to/data8'}\n"
     ]
    }
   ],
   "source": [
    "# Streams are iterable, providing (tag, packet)\n",
    "# For table-baseed streams, they are automatically tagged with the primary keys\n",
    "\n",
    "for tag, packet in table_stream1:\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject_id': 1} {'data3': '/path/to/data9', 'data4': '/path/to/data30'}\n",
      "{'subject_id': 3} {'data3': '/path/to/data10', 'data4': '/path/to/data62'}\n",
      "{'subject_id': 5} {'data3': '/path/to/data9', 'data4': '/path/to/data10'}\n"
     ]
    }
   ],
   "source": [
    "for tag, packet in table_stream2:\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating streams with mappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have streams formed, you can manipulate them by applying operations. Note that `Mapper` can only alter the *flow* of data, but can never alter or produce new data. Consequently any `Mapper` operation can be described in terms of (1) alteration of packet `tag`, (2) alteration of a packet key (argument) names, and/or (3) (re)association of an existing path with packet key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map keys\n",
    "As we will see shortly, the packet key-value pair is used as is to invoke `FunctionPod` and thus you would need the keys to match exactly the allowed named arguments for the function. You can easily change the name of the packet key using `MapKeys` operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal_id': 1} {'dataA': '/path/to/data1', 'dataB': '/path/to/data2'}\n",
      "{'animal_id': 2} {'dataA': '/path/to/data3', 'dataB': '/path/to/data4'}\n",
      "{'animal_id': 3} {'dataA': '/path/to/data5', 'dataB': '/path/to/data6'}\n",
      "{'animal_id': 4} {'dataA': '/path/to/data7', 'dataB': '/path/to/data8'}\n"
     ]
    }
   ],
   "source": [
    "# create a new stream mapping packet keys\n",
    "key_mapper = MapKeys(key_map={'data1': 'dataA', 'data2': 'dataB'})\n",
    "\n",
    "for tag, packet in key_mapper(table_stream1):\n",
    "    print(tag, packet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map tags\n",
    "Each packet in the stream is associated with a tag (often derived from the data source). These tags are used to transiently identify the packet and will be used when joining multiple streams (as we will see shortly in `Join` operation). You can manipulate the tags using `MapTags` operation, much like `MapKeys` but operating on the tags for each packaet under a uniform renaming rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject_id': 1} {'data1': '/path/to/data1', 'data2': '/path/to/data2'}\n",
      "{'subject_id': 2} {'data1': '/path/to/data3', 'data2': '/path/to/data4'}\n",
      "{'subject_id': 3} {'data1': '/path/to/data5', 'data2': '/path/to/data6'}\n",
      "{'subject_id': 4} {'data1': '/path/to/data7', 'data2': '/path/to/data8'}\n"
     ]
    }
   ],
   "source": [
    "retagged_stream = MapTags(table_stream, tag_map={'animal_id': 'subject_id'})\n",
    "\n",
    "for tag, packet in retagged_stream:\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining multiple streams into a single stream\n",
    "You can combine multiple streams into one by using `Join` operation, matching packets from each constitutent stream based on matching tag. If tags from two streams have shared key, the value must be identical for all shared keys in order for the two packets to be matched and used to create a new merged packet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal_id': 1, 'subject_id': 1} {'data1': '/path/to/data1', 'data2': '/path/to/data2', 'data3': '/path/to/data9', 'data4': '/path/to/data30'}\n",
      "{'animal_id': 1, 'subject_id': 3} {'data1': '/path/to/data1', 'data2': '/path/to/data2', 'data3': '/path/to/data10', 'data4': '/path/to/data62'}\n",
      "{'animal_id': 1, 'subject_id': 5} {'data1': '/path/to/data1', 'data2': '/path/to/data2', 'data3': '/path/to/data9', 'data4': '/path/to/data10'}\n",
      "{'animal_id': 2, 'subject_id': 1} {'data1': '/path/to/data3', 'data2': '/path/to/data4', 'data3': '/path/to/data9', 'data4': '/path/to/data30'}\n",
      "{'animal_id': 2, 'subject_id': 3} {'data1': '/path/to/data3', 'data2': '/path/to/data4', 'data3': '/path/to/data10', 'data4': '/path/to/data62'}\n",
      "{'animal_id': 2, 'subject_id': 5} {'data1': '/path/to/data3', 'data2': '/path/to/data4', 'data3': '/path/to/data9', 'data4': '/path/to/data10'}\n",
      "{'animal_id': 3, 'subject_id': 1} {'data1': '/path/to/data5', 'data2': '/path/to/data6', 'data3': '/path/to/data9', 'data4': '/path/to/data30'}\n",
      "{'animal_id': 3, 'subject_id': 3} {'data1': '/path/to/data5', 'data2': '/path/to/data6', 'data3': '/path/to/data10', 'data4': '/path/to/data62'}\n",
      "{'animal_id': 3, 'subject_id': 5} {'data1': '/path/to/data5', 'data2': '/path/to/data6', 'data3': '/path/to/data9', 'data4': '/path/to/data10'}\n",
      "{'animal_id': 4, 'subject_id': 1} {'data1': '/path/to/data7', 'data2': '/path/to/data8', 'data3': '/path/to/data9', 'data4': '/path/to/data30'}\n",
      "{'animal_id': 4, 'subject_id': 3} {'data1': '/path/to/data7', 'data2': '/path/to/data8', 'data3': '/path/to/data10', 'data4': '/path/to/data62'}\n",
      "{'animal_id': 4, 'subject_id': 5} {'data1': '/path/to/data7', 'data2': '/path/to/data8', 'data3': '/path/to/data9', 'data4': '/path/to/data10'}\n"
     ]
    }
   ],
   "source": [
    "joined_stream = Join(table_stream, table_stream2)\n",
    "\n",
    "for tag, packet in joined_stream:\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you see that every single possible combination of the two streams are found because the two streams did **not** share any common tag keys, and therefore performed full multiplexing. You can rename one of the tag keys so that they can be matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal_id': 1} {'data1': '/path/to/data1', 'data2': '/path/to/data2', 'data3': '/path/to/data9', 'data4': '/path/to/data30'}\n",
      "{'animal_id': 3} {'data1': '/path/to/data5', 'data2': '/path/to/data6', 'data3': '/path/to/data10', 'data4': '/path/to/data62'}\n"
     ]
    }
   ],
   "source": [
    "renamed_stream = MapTags(table_stream2, tag_map={'subject_id': 'animal_id'})\n",
    "joined_stream = Join(table_stream, renamed_stream)\n",
    "\n",
    "for tag, packet in joined_stream:\n",
    "    print(tag, packet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying function on a stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streams are not too useful if it can be easily operated on. You can create a `FunctionPod` by wrapping a plain Python function, and the resulting function pod can operate on a stream, applying the wrapped function on each packet, one at a time. Note that the function does **not** see the tag associated with the packet  -- function should strictly operate using information in the packet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data1, data2):\n",
    "    print('\\n\\nFunction was called!')\n",
    "    print(f'Processing data1 from {data1}')\n",
    "    print(f'Processing data2 from {data2}')\n",
    "    return '/path/to/new/output'\n",
    "\n",
    "\n",
    "# create a function pod\n",
    "function_pod = FunctionPod(process_data, output_keys=['output_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once function pod is available, you can execute it on any compatible stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data1\n",
      "Processing data2 from /path/to/data2\n",
      "{'animal_id': 1} {'output_path': '/path/to/new/output'}\n",
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data3\n",
      "Processing data2 from /path/to/data4\n",
      "{'animal_id': 2} {'output_path': '/path/to/new/output'}\n",
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data5\n",
      "Processing data2 from /path/to/data6\n",
      "{'animal_id': 3} {'output_path': '/path/to/new/output'}\n",
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data7\n",
      "Processing data2 from /path/to/data8\n",
      "{'animal_id': 4} {'output_path': '/path/to/new/output'}\n"
     ]
    }
   ],
   "source": [
    "# apply the function pod on a stream\n",
    "processed_stream = function_pod(table_stream)\n",
    "\n",
    "for tag, packet in processed_stream:\n",
    "    print(tag, packet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data9\n",
      "Processing data2 from /path/to/data30\n",
      "{'subject_id': 1} {'output_path': '/path/to/new/output'}\n",
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data10\n",
      "Processing data2 from /path/to/data62\n",
      "{'subject_id': 3} {'output_path': '/path/to/new/output'}\n",
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data9\n",
      "Processing data2 from /path/to/data10\n",
      "{'subject_id': 5} {'output_path': '/path/to/new/output'}\n"
     ]
    }
   ],
   "source": [
    "# map second table stream to match the expected packet keys\n",
    "mapped_stream = MapKeys(table_stream2, key_map={'data3': 'data1', 'data4': 'data2'})\n",
    "\n",
    "# apply the function pod on the mapped stream\n",
    "processed_stream2 = function_pod(mapped_stream)\n",
    "\n",
    "for tag, packet in processed_stream2:\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that function pod operates fine as long as the incoming packet has compatible keys with the function. As tags are not passed into the function pod, the fact that above two examples had distinct types of tags does not matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using storage-backed function pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althought the vanilla function pod `FunctionPod` illustrates the core principle of a function pod, they lack many useful features such as output storage and memoization. To use such features, you have to use a storaged-backed function pod. Here we are going to explore using DJ table-backed function pod called `DJFunctionPod`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orcabridge.dj.pod import DJFunctionPod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference between `DJFunctionPod` and `FunctionPod` is that the former is table-backed and therefore can store its output in a database table. For this reason, when instantiating a `DJFunctionPod`, you have to supply both a DataJoint schema and a valid table name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj_fpod = DJFunctionPod(process_data, output_keys=['output_path'], schema=schema, name='processed_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once created, you can use DJ function pod just like an ordinary function pod. However, it is keeping track and storing all computation outputs behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal_id': 1} {'output_path': '/path/to/new/output'}\n",
      "{'animal_id': 2} {'output_path': '/path/to/new/output'}\n",
      "{'animal_id': 3} {'output_path': '/path/to/new/output'}\n",
      "{'animal_id': 4} {'output_path': '/path/to/new/output'}\n"
     ]
    }
   ],
   "source": [
    "# apply the function pod on a stream\n",
    "processed_stream = dj_fpod(table_stream)\n",
    "\n",
    "for tag, packet in processed_stream:\n",
    "    print(tag, packet)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can appreciate the memoization if you run same computation twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'animal_id': 1} {'output_path': '/path/to/new/output'}\n",
      "{'animal_id': 2} {'output_path': '/path/to/new/output'}\n",
      "{'animal_id': 3} {'output_path': '/path/to/new/output'}\n",
      "{'animal_id': 4} {'output_path': '/path/to/new/output'}\n"
     ]
    }
   ],
   "source": [
    "# Calling the function pod on the same stream\n",
    "processed_stream = dj_fpod(table_stream)\n",
    "\n",
    "for tag, packet in processed_stream:\n",
    "    print(tag, packet)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when called the second time, function was actually **not** invoked. Rather, the stored or *memoized* result from the previous invocation was returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with regular function pod, you can run the pod on a stream with different tags (but with compatible packet keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data9\n",
      "Processing data2 from /path/to/data30\n",
      "{'subject_id': 1} {'output_path': '/path/to/new/output'}\n",
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data10\n",
      "Processing data2 from /path/to/data62\n",
      "{'subject_id': 3} {'output_path': '/path/to/new/output'}\n",
      "\n",
      "\n",
      "Function was called!\n",
      "Processing data1 from /path/to/data9\n",
      "Processing data2 from /path/to/data10\n",
      "{'subject_id': 5} {'output_path': '/path/to/new/output'}\n"
     ]
    }
   ],
   "source": [
    "mapped_stream = MapKeys(table_stream2, key_map={'data3': 'data1', 'data4': 'data2'})\n",
    "\n",
    "for tag, packet in dj_fpod(mapped_stream):\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stroage-backed function pod can serve as a stream, thus sourcing data to other operations and pods. In this case, function pod returns all stored past results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'processed_data_uuid': UUID('115b2b23-3262-278e-2b9d-350d484e68b6')} {'input_files': 'data1:/path/to/data1,data2:/path/to/data2', 'output_path': '/path/to/new/output'}\n",
      "{'processed_data_uuid': UUID('2c54462e-568a-196b-8559-65621e839c9a')} {'input_files': 'data1:/path/to/data5,data2:/path/to/data6', 'output_path': '/path/to/new/output'}\n",
      "{'processed_data_uuid': UUID('4de4316d-19d7-f92f-a6c2-010e388f39b3')} {'input_files': 'data1:/path/to/data9,data2:/path/to/data30', 'output_path': '/path/to/new/output'}\n",
      "{'processed_data_uuid': UUID('72c339d7-150c-fb7c-233e-7a8e0e030a63')} {'input_files': 'data1:/path/to/data3,data2:/path/to/data4', 'output_path': '/path/to/new/output'}\n",
      "{'processed_data_uuid': UUID('93f27a8c-0a9d-d18a-f2ca-6e4a6a7ce495')} {'input_files': 'data1:/path/to/data7,data2:/path/to/data8', 'output_path': '/path/to/new/output'}\n",
      "{'processed_data_uuid': UUID('a3a151fa-330a-1cf3-f5fa-0da62e00dd83')} {'input_files': 'data1:/path/to/data9,data2:/path/to/data10', 'output_path': '/path/to/new/output'}\n",
      "{'processed_data_uuid': UUID('a7e4bd24-ea13-8628-9111-c3b289079337')} {'input_files': 'data1:/path/to/data10,data2:/path/to/data62', 'output_path': '/path/to/new/output'}\n"
     ]
    }
   ],
   "source": [
    "for tag, packet in dj_fpod:\n",
    "    print(tag, packet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Function was called!\n",
      "Parsing data from /path/to/new/output\n",
      "{'processed_data_uuid': UUID('115b2b23-3262-278e-2b9d-350d484e68b6')} {'parsed_path': '/parsed/output/output_parsed'}\n",
      "{'processed_data_uuid': UUID('2c54462e-568a-196b-8559-65621e839c9a')} {'parsed_path': '/parsed/output/output_parsed'}\n",
      "{'processed_data_uuid': UUID('4de4316d-19d7-f92f-a6c2-010e388f39b3')} {'parsed_path': '/parsed/output/output_parsed'}\n",
      "{'processed_data_uuid': UUID('72c339d7-150c-fb7c-233e-7a8e0e030a63')} {'parsed_path': '/parsed/output/output_parsed'}\n",
      "{'processed_data_uuid': UUID('93f27a8c-0a9d-d18a-f2ca-6e4a6a7ce495')} {'parsed_path': '/parsed/output/output_parsed'}\n",
      "{'processed_data_uuid': UUID('a3a151fa-330a-1cf3-f5fa-0da62e00dd83')} {'parsed_path': '/parsed/output/output_parsed'}\n",
      "{'processed_data_uuid': UUID('a7e4bd24-ea13-8628-9111-c3b289079337')} {'parsed_path': '/parsed/output/output_parsed'}\n"
     ]
    }
   ],
   "source": [
    "def parse_data(source_data):\n",
    "    print('\\n\\nFunction was called!')\n",
    "    print(f'Parsing data from {source_data}')\n",
    "    return '/parsed/output/' + (source_data.split(\"/\")[-1]) + '_parsed'\n",
    "\n",
    "dj_fpod2 = DJFunctionPod(parse_data, output_keys=['parsed_path'], schema=schema, name='parsed_data')\n",
    "\n",
    "for tag, packet, in dj_fpod2(MapKeys(dj_fpod, key_map={'output_path': 'source_data'})):\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that pod execution are stored/memoized based on the content of the packet with no reliance on the tag. Therefore, if two or more packets with distinct tags but with identical contents are processed, only the first instance will be computed and the subsequent ones return the memoized values, saving on computation. In the above example, the function `parse_data` was called only once as all invocations involved identical packet as an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaining together DJ-backed function pods do **not** result in foreign-key dependency to be formed between the two tables. The two data-backing tables will remain independent of each other. We will soon see how you can automatically create a DJ relational pipeline *representation* of a pipeline formed from streams, operations and pods, allowing for query to be performed using DataJoint query engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"768pt\" height=\"43pt\" viewBox=\"0.00 0.00 768.00 43.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 39)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-39 764,-39 764,4 -4,4\"/>\n",
       "<!-- `enigma_orcabridge_test`.`parsed_data` -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>`enigma_orcabridge_test`.`parsed_data`</title>\n",
       "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"263,-35 0,-35 0,0 263,0 263,-35\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-15.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">`enigma_orcabridge_test`.`parsed_data`</text>\n",
       "</g>\n",
       "<!-- `enigma_orcabridge_test`.`processed_data` -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>`enigma_orcabridge_test`.`processed_data`</title>\n",
       "<polygon fill=\"#00ff00\" fill-opacity=\"0.188235\" stroke=\"#00ff00\" stroke-opacity=\"0.188235\" points=\"563.5,-35 281.5,-35 281.5,0 563.5,0 563.5,-35\"/>\n",
       "<text text-anchor=\"start\" x=\"289.5\" y=\"-15.4\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"12.00\" fill=\"darkgreen\">`enigma_orcabridge_test`.`processed_data`</text>\n",
       "</g>\n",
       "<!-- SampleData2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>SampleData2</title>\n",
       "<g id=\"a_node3\"><a xlink:title=\"subject_id           \r------------------------------\rdata3                \rdata4                \r\">\n",
       "<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"transparent\" points=\"665,-35 582,-35 582,0 665,0 665,-35\"/>\n",
       "<text text-anchor=\"start\" x=\"590\" y=\"-16\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">SampleData2</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- SampleData -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>SampleData</title>\n",
       "<g id=\"a_node4\"><a xlink:title=\"animal_id            \r------------------------------\rdata1                \rdata2                \r\">\n",
       "<polygon fill=\"#000000\" fill-opacity=\"0.125490\" stroke=\"transparent\" points=\"760,-35 683,-35 683,0 760,0 760,-35\"/>\n",
       "<text text-anchor=\"start\" x=\"691\" y=\"-16\" font-family=\"arial\" text-decoration=\"underline\" font-size=\"10.00\">SampleData</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<datajoint.diagram.Diagram at 0x7efec9332d10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dj.Diagram(schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
